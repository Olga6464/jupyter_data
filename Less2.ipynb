{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Урок 2. Парсинг HTML. BeautifulSoup, MongoDB (ДЗ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо собрать информацию о вакансиях на вводимую должность (используем input или через аргументы) с сайтов Superjob и HH. Приложение должно анализировать несколько страниц сайта (также вводим через input или аргументы). Получившийся список должен содержать в себе минимум:\n",
    "* Наименование вакансии.\n",
    "* Предлагаемую зарплату (отдельно минимальную, максимальную и валюту).\n",
    "* Ссылку на саму вакансию.\n",
    "* Сайт, откуда собрана вакансия.\n",
    "\n",
    "По желанию можно добавить ещё параметры вакансии (например, работодателя и расположение). Структура должна быть одинаковая для вакансий с обоих сайтов. Общий результат можно вывести с помощью dataFrame через pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs # для работы с HTML\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поиск QA, г. Санкт-Петербург"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "##https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&selary=&st=searchVacancy&text=QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_link = 'https://spb.hh.ru'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = 'QA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'clusters':'true',\\\n",
    "          'enable_snippets':'true',\\\n",
    "          'selary':'', \\\n",
    "          'st': 'searchVacancy',\\\n",
    "          'text': prof,\n",
    "          'page' : ' '\n",
    "                  \n",
    "         } #передадим параметры в словарик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(main_link + '/search/vacancy/',params=params,headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 200\n"
     ]
    }
   ],
   "source": [
    "if response.status_code == 200:\n",
    "    print(f' {response.status_code}')\n",
    "else:\n",
    "    dom = bs(response.text, 'html.parser')\n",
    "    page_block = dom.find('div',{'data-qa': 'pager-block'})\n",
    "    if not page_blok:\n",
    "        last_page = 1\n",
    "    else:\n",
    "        last_page = int(page_block.find_all('a',{'class':'HH-Pager-Control'})[-2].getText())\n",
    "        print(f'last_page {last_page}')\n",
    "    \n",
    "    for page in rage(0, last_page):\n",
    "        params['page'] = page\n",
    "        response = requests.get(main_link + '/search/vacancy/',params=paramas,headers=headers)\n",
    "        dom = bs(response.text, 'html.parser')\n",
    "        vacancy_list = dom.find_all('div', {'class': 'vacancy-serp-item'})\n",
    "        if len(vacancy_list) == 0:\n",
    "            print(f'Vacancies with QA \"{prof}\" ')\n",
    "        else:       \n",
    "            vacancies = []\n",
    "            for vacancy in vacancy_list:\n",
    "                vacancy_data = {}\n",
    "        \n",
    "                vacancy_name = vacancy.find('div', {'class': 'resume-search-item__name'}) \\\n",
    "                                      .getText() \\\n",
    "                                      .replace(u'/xa0', u' ')\n",
    "                vacancy_data['vacancy_name'] = vacancy_name\n",
    "            \n",
    "                compay_name = vacancy.find('div', {'class' : 'vacancy-serp-item__meta-info'}) \\\n",
    "                                     .find('a') \\\n",
    "                                     .getText()\n",
    "                vacancy_data['compay_name'] = compay_name\n",
    "            \n",
    "                city = vacancy.find('span', {'class': 'vacancy-serp-item__meta-info'}) \\\n",
    "                              .getText() \\\n",
    "                              .split(', ')[0]\n",
    "                vacancy_data['city'] = city\n",
    "            \n",
    "                metro = vacancy.find('span', {'class': 'vacancy-serp-item__meta-info'}).findChild()\n",
    "                if not metro:\n",
    "                    metro = None\n",
    "                else:\n",
    "                    metro = metro.getText()\n",
    "                vacancy_data['metro'] = metro\n",
    "            \n",
    "                salary = vacancy.find('div', {'class': 'vacancy-serp-item__compensation'})\n",
    "                if not salary:\n",
    "                    salary_min = None\n",
    "                    salary_max = None\n",
    "                    salary_currency = None\n",
    "                else:\n",
    "                    salary = salary.getText() \\\n",
    "                                   .replace(u'\\xa0', u' ')\n",
    "                \n",
    "                    salary = re.split(r'\\s|-', salary)\n",
    "                \n",
    "                    if salary[0] == 'до':\n",
    "                        salary_min = None\n",
    "                        salary_max = int(salary[1])\n",
    "                    elif salary[0] == 'от':\n",
    "                        salary_min = int(salary[1])\n",
    "                        salary_max = None\n",
    "                    else:\n",
    "                        salary_min = int(salary[0])\n",
    "                        salary_max = int(salary[1])\n",
    "                    \n",
    "                salary_currency = salary[2]\n",
    "                \n",
    "                vacancy_data['salary_min'] = salary_min\n",
    "                vacancy_data['salary_max'] = salary_max\n",
    "                vacancy_data['salary_currency'] = salary_currency\n",
    "            \n",
    "                vacancy_link = vacancy.find('div', {'class' : 'resume-search-item__name'}) \\\n",
    "                                      .find('a'),['href']\n",
    "                vacancy_data['vacancy_link'] = vacancy_link\n",
    "                \n",
    "                vacancies.append(vacancy_data) \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(vacancies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(vacancy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
